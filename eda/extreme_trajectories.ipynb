{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c689b2d3",
   "metadata": {
    "id": "c689b2d3"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2feca066",
   "metadata": {
    "id": "2feca066"
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    GPT2TimeLMHeadModel,\n",
    "    GPT2Tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b04d94fc",
   "metadata": {
    "id": "b04d94fc",
    "outputId": "525b4a43-f4a2-48c9-fb2f-91f738acf686"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 21:20:23.264776: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../language-modeling')\n",
    "from run_time_clm import (\n",
    "    get_checkpoint,\n",
    "    get_special_tokens,\n",
    "    get_data_paths,\n",
    "    get_dataset)\n",
    "\n",
    "sys.path.append('../text-generation')\n",
    "from generation_metrics import GenerationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd340ea0",
   "metadata": {
    "id": "dd340ea0"
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa75e7f7",
   "metadata": {
    "id": "fa75e7f7"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = int(10000)  # Hardcoded max length to avoid infinite loop\n",
    "\n",
    "MODEL_CLASSES = {\n",
    "    \"gpt2\": (GPT2TimeLMHeadModel, GPT2Tokenizer),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d75602a2",
   "metadata": {
    "id": "d75602a2"
   },
   "outputs": [],
   "source": [
    "def set_seed(args):\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "        \n",
    "def adjust_length_to_model(length, max_sequence_length):\n",
    "    if length < 0 and max_sequence_length > 0:\n",
    "        length = max_sequence_length\n",
    "    elif 0 < max_sequence_length < length:\n",
    "        length = max_sequence_length  # No generation bigger than model size\n",
    "    elif length < 0:\n",
    "        length = MAX_LENGTH  # avoid infinite loop\n",
    "    return length\n",
    "\n",
    "def simulate_brownian_bridge(B_0, B_T, num_samples, sentence_lengths, dt=0.05, mu=0.0, sigma=1.0):\n",
    "    \"\"\"Run bridge forward pinned at B_0 and B_T\"\"\"\n",
    "    if isinstance(B_0, torch.Tensor):\n",
    "        B_0 = B_0.cpu().detach().numpy()\n",
    "    if isinstance(B_T, torch.Tensor):\n",
    "        B_T = B_T.cpu().detach().numpy()\n",
    "\n",
    "    bridge = [B_0]\n",
    "    x_t = np.copy(B_0)\n",
    "    for step in range(num_samples - 2): # number of sentences\n",
    "        dim = B_0.shape[-1]\n",
    "        noise = np.sqrt(dt)*sigma*np.random.normal(mu, sigma, dim)\n",
    "        t = step/num_samples\n",
    "        x_tp1 = x_t * (1- dt/(1-t)) + (dt/(1-t))*B_T + noise\n",
    "        length_idx = step % len(sentence_lengths)\n",
    "        bridge += [x_tp1] * sentence_lengths[length_idx]\n",
    "        x_t = x_tp1\n",
    "\n",
    "    length_idx = step % len(sentence_lengths)\n",
    "    bridge += [B_T] * sentence_lengths[length_idx]\n",
    "\n",
    "    return bridge\n",
    "\n",
    "def split_text(raw_text):\n",
    "    split_pattern = \". \"\n",
    "    split_raw_text = [_ + split_pattern for _ in raw_text.split(split_pattern)]\n",
    "    split_raw_text[-1] = split_raw_text[-1].rstrip(split_pattern)\n",
    "    return split_raw_text\n",
    "\n",
    "def get_density(dataset, lm, cl_model):\n",
    "    \"\"\"Estimate density of last latent\"\"\"\n",
    "    first_latents = []\n",
    "    last_latents = []\n",
    "    length = len(dataset)\n",
    "    for text_i in range(length):\n",
    "        first_latents.append(dataset.cl_embeddings[text_i][0].detach().cpu().numpy())\n",
    "        last_latents.append(dataset.cl_embeddings[text_i][-1].detach().cpu().numpy())\n",
    "    first_latents = np.array(first_latents)\n",
    "    last_latents = np.array(last_latents)\n",
    "    return first_latents.mean(0), first_latents.std(0), last_latents.mean(0), last_latents.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0920f247",
   "metadata": {
    "id": "0920f247",
    "outputId": "e0eeb034-f77d-4b02-e7ed-f770b6b166fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--fp16'], dest='fp16', nargs=0, const=True, default=False, type=None, choices=None, help='Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit', metavar=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--model_type\",\n",
    "    default=None,\n",
    "    type=str,\n",
    "    required=True,\n",
    "    help=\"Model type selected in the list: \" + \", \".join(MODEL_CLASSES.keys()),\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--model_name_or_path\",\n",
    "    default=None,\n",
    "    type=str,\n",
    "    required=True,\n",
    "    help=\"Path to pre-trained model or shortcut name selected in the list: \" + \", \".join(MODEL_CLASSES.keys()),\n",
    ")\n",
    "\n",
    "parser.add_argument(\"--prompt\", type=str, default=\"\")\n",
    "parser.add_argument(\"--length\", type=int, default=20)\n",
    "parser.add_argument(\"--stop_token\", type=str, default=None, help=\"Token at which text generation is stopped\")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--temperature\",\n",
    "    type=float,\n",
    "    default=1.0,\n",
    "    help=\"temperature of 1.0 has no effect, lower tend toward greedy sampling\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--repetition_penalty\", type=float, default=1.0, help=\"primarily useful for CTRL model; in that case, use 1.2\"\n",
    ")\n",
    "parser.add_argument(\"--k\", type=int, default=0)\n",
    "parser.add_argument(\"--num-sentences\", type=int, default=0)\n",
    "parser.add_argument(\"--split-sentences\", type=int, default=1)\n",
    "parser.add_argument(\"--multiply-sentences\", type=int, default=1)\n",
    "parser.add_argument(\"--p\", type=float, default=0.99)\n",
    "\n",
    "parser.add_argument(\"--prefix\", type=str, default=\"\", help=\"Text added prior to input.\")\n",
    "parser.add_argument(\"--padding_text\", type=str, default=\"\", help=\"Deprecated, the use of `--prefix` is preferred.\")\n",
    "\n",
    "parser.add_argument(\"--no_eos\", action=\"store_false\", help=\"Avoid using CUDA when available\")\n",
    "parser.add_argument(\"--dryrun\", action=\"store_true\", default=False, help=\"Text added prior to input.\")\n",
    "parser.add_argument(\"--suppress_eos\", action=\"store_true\", default=False, help=\"Text added prior to input.\")\n",
    "parser.add_argument(\"--seed\", type=int, default=42, help=\"random seed for initialization\")\n",
    "parser.add_argument(\"--dataset_name\", type=str, default=\"\", help=\"Text added prior to input.\")\n",
    "parser.add_argument(\"--no_cuda\", action=\"store_true\", help=\"Avoid using CUDA when available\")\n",
    "parser.add_argument(\"--fixed_prompt\", action=\"store_true\", help=\"Avoid using CUDA when available\")\n",
    "parser.add_argument(\"--num_return_sequences\", type=int, default=1, help=\"The number of samples to generate.\")\n",
    "parser.add_argument(\"--num_intervals\", type=int, default=1, help=\"The number of samples to generate.\")\n",
    "parser.add_argument(\"--block_size\", type=int, default=1024)\n",
    "parser.add_argument(\"--use_dataset\", action=\"store_true\", default=False, help=\"Text added prior to input.\")\n",
    "parser.add_argument(\"--project\", type=str, default=\"\", help=\"Text added prior to input.\")\n",
    "parser.add_argument(\"--encoder_filepath\", type=str, required=True,default=\"\", help=\"Text added prior to input.\")\n",
    "parser.add_argument(\"--latent_dim\", type=int, default=3, help=\"random seed for initialization\")\n",
    "parser.add_argument(\"--use_random_embs\", action=\"store_true\", help=\"Avoid using CUDA when available\")\n",
    "parser.add_argument(\"--use_true_end_latent\", action=\"store_true\", help=\"Avoid using CUDA when available\")\n",
    "parser.add_argument(\"--label\", type=str, default=\"\", help=\"Text added prior to input.\")\n",
    "\n",
    "parser.add_argument(\"--method\", type=str, default=\"\", help=\"Text added prior to input.\")\n",
    "parser.add_argument(\"--first_sentence\", action=\"store_true\", help=\"Avoid using CUDA when available\")\n",
    "parser.add_argument(\"--full_section\", action=\"store_true\", help=\"Avoid using CUDA when available\")\n",
    "parser.add_argument(\"--autoregressive\", action=\"store_true\", help=\"Avoid using CUDA when available\")\n",
    "parser.add_argument(\n",
    "    \"--fp16\",\n",
    "    action=\"store_true\",\n",
    "    help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13d53740",
   "metadata": {
    "id": "13d53740"
   },
   "outputs": [],
   "source": [
    "nseed = 10\n",
    "path2repo = '/home/sheng136/workspace/myprojects/language_modeling_via_stochastic_processes/'\n",
    "\n",
    "domain = \"tickettalk\"\n",
    "latent_dim = '16'\n",
    "\n",
    "\n",
    "args = parser.parse_args(f\"\"\"--model_type=gpt2 \n",
    "                         --model_name_or_path={path2repo}/language_modeling_via_stochastic_processes/transformers/examples/pytorch/language-modeling/LM_{domain}_{latent_dim}/ \n",
    "                         --prompt=\"<|endoftext|>\" \n",
    "                         --num_return_sequences=1 \n",
    "                         --num_intervals=1000 \n",
    "                         --method=sample \n",
    "                         --stop_token=\"<|endoftext|>\" \n",
    "                         --dataset_name={domain} \n",
    "                         --encoder_filepath={path2repo}/trained_model/{domain}_encoder.ckpt \n",
    "                         --latent_dim={latent_dim} \n",
    "                         --project=LM_{domain} \n",
    "                         --no_eos\n",
    "                         --label=LM_{domain}_{latent_dim} \n",
    "                         --seed={nseed}\"\"\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5cb10a4",
   "metadata": {
    "id": "c5cb10a4",
    "outputId": "536807fd-ed6e-4b07-c501-3c82f73bc1f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/16/2022 21:20:24 - WARNING - __main__ -   device: cuda, n_gpu: 1, 16-bits training: False\n"
     ]
    }
   ],
   "source": [
    "args.device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
    "args.n_gpu = 0 if args.no_cuda else torch.cuda.device_count()\n",
    "args.use_section_null = 0\n",
    "\n",
    "logger.warning(f\"device: {args.device}, n_gpu: {args.n_gpu}, 16-bits training: {args.fp16}\")\n",
    "\n",
    "set_seed(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e06648e6",
   "metadata": {
    "id": "e06648e6"
   },
   "outputs": [],
   "source": [
    "# Initialize the model and tokenizer\n",
    "try:\n",
    "    args.model_type = args.model_type.lower()\n",
    "    model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\n",
    "except KeyError:\n",
    "    raise KeyError(\"the model {} you specified is not supported. You are welcome to add it and open a PR :)\")\n",
    "\n",
    "tokenizer = tokenizer_class.from_pretrained(args.model_name_or_path)\n",
    "model = model_class.from_pretrained(args.model_name_or_path)\n",
    "model.to(args.device)\n",
    "\n",
    "model.transformer._config.use_contrastive_embeddings = True\n",
    "\n",
    "if args.suppress_eos:\n",
    "    bad_words_ids = [[tokenizer.eos_token_id]]\n",
    "else:\n",
    "    bad_words_ids = None\n",
    "\n",
    "if args.no_eos:\n",
    "    min_length = 1023\n",
    "else:\n",
    "    min_length= 10 # default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "425960e2",
   "metadata": {
    "id": "425960e2",
    "outputId": "34be76ac-55de-4524-c129-f3f583e41ee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old tokenizer size:  50260\n",
      "Not adding because it's already contained\n",
      "New tokenizer size:  50260\n"
     ]
    }
   ],
   "source": [
    "SECTION_IDS, SPECIAL_TOKENS, tokenizer = get_special_tokens(\n",
    "        dataset_name=args.dataset_name, tokenizer=tokenizer)\n",
    "\n",
    "model.transformer.special_tokens = SPECIAL_TOKENS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeab8c1f",
   "metadata": {
    "id": "eeab8c1f"
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "863a9f0a",
   "metadata": {
    "id": "863a9f0a",
    "outputId": "22675e75-353e-4c4f-db74-73f701f3556a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2OUEncoder(\n",
       "  (model): GPT2Model(\n",
       "    (wte): Embedding(50260, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (mlp): Linear(in_features=768, out_features=128, bias=True)\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=16, bias=True)\n",
       "  )\n",
       "  (log_q): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (1): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       "  (C_eta): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = 'gpt2'\n",
    "CL_MODEL = get_checkpoint(\n",
    "        dataset_name=args.dataset_name,\n",
    "        latent_dim=args.latent_dim,\n",
    "        sec_id=True,\n",
    "        token_size=len(tokenizer),\n",
    "        base_model=base_model,\n",
    "        filepath=args.encoder_filepath\n",
    "    )# .to(cpu_device)\n",
    "CL_MODEL.to(args.device)\n",
    "CL_MODEL.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd8a13f",
   "metadata": {
    "id": "1cd8a13f"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18f4af66",
   "metadata": {
    "id": "18f4af66",
    "outputId": "ed3cb4b0-200f-4468-9e8c-7e4b1c1d049f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args: Namespace(autoregressive=False, block_size=1024, dataset_name='tickettalk', device=device(type='cuda'), dryrun=False, encoder_filepath='/home/sheng136/workspace/myprojects/language_modeling_via_stochastic_processes//trained_model/tickettalk_encoder.ckpt', first_sentence=False, fixed_prompt=False, fp16=False, full_section=False, k=0, label='LM_tickettalk_16', latent_dim=16, length=20, method='sample', model_name_or_path='/home/sheng136/workspace/myprojects/language_modeling_via_stochastic_processes//language_modeling_via_stochastic_processes/transformers/examples/pytorch/language-modeling/LM_tickettalk_16/', model_type='gpt2', multiply_sentences=1, n_gpu=1, no_cuda=False, no_eos=False, num_intervals=1000, num_return_sequences=1, num_sentences=0, p=0.99, padding_text='', prefix='', project='LM_tickettalk', prompt='\"<|endoftext|>\"', repetition_penalty=1.0, seed=10, split_sentences=1, stop_token='\"<|endoftext|>\"', suppress_eos=False, temperature=1.0, use_dataset=False, use_random_embs=False, use_section_null=0, use_true_end_latent=False)\n",
      "LOADING MOVIE TM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sheng136/workspace/myprojects/language_modeling_via_stochastic_processes/language_modeling_via_stochastic_processes/transformers/src/transformers/data/datasets/language_modeling.py:64: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num examples 2376\n",
      "num filtered 0\n",
      "Lengths\n",
      "examples\n",
      "<|endoftext|> [ USER ] hi....am buying a ticket tonight so we go and see a movie at AMC mountain 16 [ ASSISTANT ] No problem. Is there a particular type of movie youâ€™re looking for? [ USER ] hhhmmmmm not at all. i dont have any in mind for now [ ASSISTANT ] Sure. I can help with that. Let me listings at AMC Mercado 24. [ USER ] sure you can but i want to see the movie at AMC mountain 16 [ ASSISTANT ] Oh, sorry about that. So youâ€™re interested in action films at AMC Mountain 16, right? [ USER ] yeah [ ASSISTANT ] OK. I show one action movie playing at AMC Mountain 16: No Time To Die. Remaining showtimes are 4:30pm, 6:40pm and 9:10pm. Does any of those work? [ USER ] yeah but 9.10pm will be perfect for me [ ASSISTANT ] Great. And how many tickets? [ USER ] myself and two other persons are going to see a movie [ ASSISTANT ] All right. Let me confirm that youâ€™d like three tickets for No Time To Die at AMC Mountain 16 tonight at 9:10pm. Is that all correct? [ USER ] yeah [ ASSISTANT ] Is it OK to go ahead and purchase these tickets? [ USER ] yes you can [ ASSISTANT ] OK. Your tickets are purchased and details for how to proceed have been sent to your email address. Can I help with anything else? [ USER ] ok thanks but i dont need anything again [ ASSISTANT ] OK. Enjoy your movie!  <|endoftext|>\n",
      "<|endoftext|> [ USER ] Purchase tickets for Bad Boys for Life, please [ ASSISTANT ] Sure. What time would you like to go? [ USER ] What times are available around 7? [ ASSISTANT ] There are several showtimes around 7:00 PM. There is a 6:45 PM, 7:50 PM, and 8:00 PM. [ USER ] Is there a 7:00 PM showtime? [ ASSISTANT ] No. There is no 7:00 PM showtime? [ USER ] Okay. What about an 7:30 PM showtime? [ ASSISTANT ] There is no 7:30 PM showtime? [ USER ] Are there any 7:00 PM showtimes around Dallas? [ ASSISTANT ] The closest 7:00 PM showtime is 20 miles away. [ USER ] What is the next available showtime for Bad Boys for life or Knives Out? [ ASSISTANT ] There is a 7:50 PM showtime for Bad Boys for life and a 8:30 PM showtime for Knives Out. [ USER ] Book tickets for the 8:30 PM showtime Knives Out. [ ASSISTANT ] How many tickets would you like purchased? [ USER ] Five tickets. [ ASSISTANT ] There are not Five Tickets available for the 8:30 PM showtime of Knives Out. [ USER ] How many tickets are available? [ ASSISTANT ] According to the movie theater app there are only three tickets left for the 8:30 PM showtime of Knives Out. [ USER ] Okay. How many tickets are available for the 7:50 PM showing of Bad Boys for Life? [ ASSISTANT ] There is only one ticket available. [ USER ] Are there any options available within 10 miles? [ ASSISTANT ] There are no options available within 10 miles [ USER ] Okay. Never mind. Do not purchase any tickets.  <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "assert args.dataset_name\n",
    "from language_modeling_via_stochastic_processes.src import constants\n",
    "print(f'Args: {args}')\n",
    "train_path, _, eval_path = get_data_paths(args)\n",
    "train_dataset = get_dataset(\n",
    "    args=args,\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=train_path,\n",
    "    special_words=SECTION_IDS,\n",
    "    cache_dir=constants.PATH2HUGGINGFACE,\n",
    "    cl_model=CL_MODEL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0efed943",
   "metadata": {
    "id": "0efed943",
    "outputId": "a58242c8-cfc7-408f-b78c-58916c113bfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING MOVIE TM\n",
      "num examples 1188\n",
      "num filtered 0\n",
      "Lengths\n",
      "examples\n",
      "<|endoftext|> [ USER ] hai sir, we all are like to watch a comedy movie.. we dont like action movie.. i think.. is there is there movie is action movie? [ ASSISTANT ] No problem. Is there a particular type of movie youâ€™re looking for? [ USER ] wow supper... i dont expect this... are you sure sir this movie is a comedy movie? then if are u help me to listinings at amc mercada 24 [ ASSISTANT ] Sure. I can help with that. Let me listings at AMC Mercado 24. [ USER ] sir again i told you... i want watch comedy movie.. is there is the amc mountain 16 is right or wrong? [ ASSISTANT ] Oh, sorry about that. So youâ€™re interested in action films at AMC Mountain 16, right? [ USER ] okay sir.. i was compromise my family to watch action movie now... because i want to see tha amc mountain 16 now [ ASSISTANT ] OK. I show one action movie playing at AMC Mountain 16: No Time To Die. Remaining showtimes are 4:30pm, 6:40pm and 9:10pm. Does any of those work? [ USER ] i have free in 9.10 pm for my busy schedule... so me and my family members are come to your theater in 9.10 pm [ ASSISTANT ] Great. And how many tickets? [ USER ] yeah i want 3 tickets for me and my bro & sis [ ASSISTANT ] All right. Let me confirm that youâ€™d like three tickets for No Time To Die at AMC Mountain 16 tonight at 9:10pm. Is that all correct? [ USER ] mm kk sir.. i dont leave that time [ ASSISTANT ] Is it OK to go ahead and purchase these tickets? [ USER ] mm kk sir.. i will purchase the 3 tickets.. [ ASSISTANT ] OK. Your tickets are purchased and details for how to proceed have been sent to your email address. Can I help with anything else? [ USER ] still your helping is very thank ful sir... then i will manage it.. u dont help me.. [ ASSISTANT ] OK. Enjoy your movie!  <|endoftext|>\n",
      "<|endoftext|> [ USER ] Hello! I would like to get some movie tickets. [ ASSISTANT ] Good morning! What movie would you like me to book tickets for? [ USER ] I would like to watch Uncut Gems. [ ASSISTANT ] Great! What's the address or name of the theater where you want to watch Uncut Gems? [ USER ] The AMC on Cypress. It's the only theater in my area. [ ASSISTANT ] Awesome, what day would you like the tickets for? [ USER ] This Friday. [ ASSISTANT ] The AMC at 1600 Calhoun Rd, Cypress, TX, has the following showtimes for Uncut Gems: 12:00 PM, 01:00 PM and 09:30 PM. [ USER ] None of those work for me. Isn't there a showtime at 05:00 PM or 02:00 PM. [ ASSISTANT ] The theater you selected doesn't have those showtimes. I'm sorry. Would you like to see showtimes on other theaters or for other movies? [ USER ] Are there any showings of Doctor Doolittle in that same AMC? [ ASSISTANT ] For this Friday as well? [ USER ] Yes, at 05:00 PM or 02:00 PM. [ ASSISTANT ] There is a 02:00 PM show for Doctor Doolittle. [ USER ] Awesome! [ ASSISTANT ] How many tickets would you like me to book? [ USER ] Six. [ ASSISTANT ] I'm sorry, there are only four seats available for the 02:00 PM show. Would you like me to look at the Saturday shows instead? [ USER ] No, it's ok. I'll see if my friends want to watch something else. [ ASSISTANT ] Sorry for the inconvenience!  <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "eval_dataset = get_dataset(\n",
    "        args=args,\n",
    "        tokenizer=tokenizer,\n",
    "        file_path=eval_path,\n",
    "        special_words=SECTION_IDS,\n",
    "        cache_dir=constants.PATH2HUGGINGFACE,\n",
    "        cl_model=CL_MODEL,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02c6f625",
   "metadata": {
    "id": "02c6f625"
   },
   "outputs": [],
   "source": [
    "# Estimate density for last sentence\n",
    "first_latent_mu, first_latent_std, last_latent_mu, last_latent_std = get_density(dataset=train_dataset, lm=model, cl_model=CL_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f0a7333",
   "metadata": {
    "id": "0f0a7333"
   },
   "outputs": [],
   "source": [
    "num_intervals = len(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0794c477",
   "metadata": {
    "id": "0794c477",
    "outputId": "38f8217d-90b3-4ca3-b937-e32429f93a00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1188"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15dbb041",
   "metadata": {
    "id": "15dbb041",
    "outputId": "34903170-fbc0-4034-b613-b0f92bf0c124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last latent mu [-0.52328944  0.5134945   0.5024361  -0.508544    0.5275813   0.5180528\n",
      "  0.5092071  -0.51341796  0.5401892   0.52739847 -0.5112348   0.53281057\n",
      " -0.51549774  0.5339563   0.5201655   0.5258357 ]\n",
      "last latent std [0.20150964 0.19876935 0.1916553  0.1879684  0.19223699 0.19855234\n",
      " 0.19538742 0.19835728 0.2010545  0.19634782 0.19453451 0.19091173\n",
      " 0.1909538  0.18812436 0.19124323 0.19830342]\n"
     ]
    }
   ],
   "source": [
    "print(\"last latent mu\", last_latent_mu)\n",
    "print(\"last latent std\", last_latent_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66e3d9f2",
   "metadata": {
    "id": "66e3d9f2",
    "outputId": "d00e8b39-a7fe-4177-ac19-86a8960fbfcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking example embeddings: tensor([-0.1766,  0.1473,  0.1222, -0.1754,  0.1808,  0.1625,  0.1590, -0.1451,\n",
      "         0.1540,  0.1787, -0.1800,  0.1995, -0.1605,  0.1790,  0.1835,  0.1909],\n",
      "       device='cuda:0')\n",
      "Checking example embeddings: tensor([-0.7280,  0.7133,  0.6992, -0.6989,  0.7188,  0.7198,  0.7100, -0.7148,\n",
      "         0.7379,  0.7346, -0.7065,  0.7187, -0.7052,  0.7223,  0.7213,  0.7226],\n",
      "       device='cuda:0')\n",
      "Checking example embeddings: tensor([-0.1025,  0.0956,  0.0594, -0.1013,  0.0859,  0.0948,  0.1046, -0.0729,\n",
      "         0.0904,  0.1108, -0.1112,  0.1333, -0.1023,  0.0926,  0.1122,  0.0967],\n",
      "       device='cuda:0')\n",
      "Checking example embeddings: tensor([-0.2416,  0.2438,  0.2398, -0.2420,  0.2593,  0.2482,  0.2493, -0.2351,\n",
      "         0.2556,  0.2598, -0.2406,  0.2530, -0.2498,  0.2663,  0.2442,  0.2473],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking example embeddings: {}\".format(eval_dataset.cl_embeddings[0][0]))\n",
    "print(\"Checking example embeddings: {}\".format(eval_dataset.cl_embeddings[0][-1]))\n",
    "print(\"Checking example embeddings: {}\".format(eval_dataset.cl_embeddings[-1][0]))\n",
    "print(\"Checking example embeddings: {}\".format(eval_dataset.cl_embeddings[-1][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a060da1e",
   "metadata": {
    "id": "a060da1e",
    "outputId": "6cde5e94-5712-4d71-d300-8b60db223ac6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_dataset.cl_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2252533",
   "metadata": {
    "id": "d2252533",
    "outputId": "787c7e27-f1f4-4a99-f9ef-03601384567a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.cl_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b856c558",
   "metadata": {
    "id": "b856c558",
    "outputId": "a478aee9-8134-4a11-d22f-48f61f8ef8c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[ USER ] I would like to buy three tickets for tonight. [ ASSISTANT ] No problem. Is there a particular type of movie youâ€™re looking for? [ USER ] My two buds and I are going. Probably an action movie. Nothing mushy! [ ASSISTANT ] Sure. I can help with that. Let me check listings at AMC Mercado 24. [ USER ] Oh, Pardon me. We wanted to go to the AMC Mountain 16. [ ASSISTANT ] Oh, sorry about that. So youâ€™re interested in action films at AMC Mountain 16, right? [ USER ] You are correct! [ ASSISTANT ] OK. I see one action movie playing at AMC Mountain 16: No Time To Die. Remaining showtimes are 4:30pm, 6:40pm and 9:10pm. Does any of those work? [ USER ] That sounds good. We'd probably want to go to the 9:10pm showing. [ ASSISTANT ] Great. And how many tickets? [ USER ] My friends Joe, Bob, and I are going to the movie. So, 3. [ ASSISTANT ] All right. Let me confirm that youâ€™d like three tickets for No Time To Die at AMC Mountain 16 tonight at 9:10pm. Is that all correct? [ USER ] Yes, that is correct! [ ASSISTANT ] Is it OK to go ahead and purchase these tickets? [ USER ] Yes, please! [ ASSISTANT ] OK. Your tickets are purchased and details for how to proceed have been sent to your email address. Can I help with anything else? [ USER ] No. Thank you. You have been very helpful. [ ASSISTANT ] OK. Enjoy your movie! \""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset.cl_texts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb6b0ab0",
   "metadata": {
    "id": "eb6b0ab0",
    "outputId": "01d2a8eb-8608-4b0e-d873-6a3eb8d48e92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|endoftext|> [ USER ] I would like to buy three tickets for tonight. [ ASSISTANT ] No problem. Is there a particular type of movie youâ€™re looking for? [ USER ] My two buds and I are going. Probably an action movie. Nothing mushy! [ ASSISTANT ] Sure. I can help with that. Let me check listings at AMC Mercado 24. [ USER ] Oh, Pardon me. We wanted to go to the AMC Mountain 16. [ ASSISTANT ] Oh, sorry about that. So youâ€™re interested in action films at AMC Mountain 16, right? [ USER ] You are correct! [ ASSISTANT ] OK. I see one action movie playing at AMC Mountain 16: No Time To Die. Remaining showtimes are 4:30pm, 6:40pm and 9:10pm. Does any of those work? [ USER ] That sounds good. We'd probably want to go to the 9:10pm showing. [ ASSISTANT ] Great. And how many tickets? [ USER ] My friends Joe, Bob, and I are going to the movie. So, 3. [ ASSISTANT ] All right. Let me confirm that youâ€™d like three tickets for No Time To Die at AMC Mountain 16 tonight at 9:10pm. Is that all correct? [ USER ] Yes, that is correct! [ ASSISTANT ] Is it OK to go ahead and purchase these tickets? [ USER ] Yes, please! [ ASSISTANT ] OK. Your tickets are purchased and details for how to proceed have been sent to your email address. Can I help with anything else? [ USER ] No. Thank you. You have been very helpful. [ ASSISTANT ] OK. Enjoy your movie!  <|endoftext|>\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset.raw_texts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c05926c",
   "metadata": {
    "id": "2c05926c",
    "outputId": "ceee143f-5794-4e08-f402-f5256662c389"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1188/1188 [00:00<00:00, 27868.97it/s]\n"
     ]
    }
   ],
   "source": [
    "for num_example in tqdm.tqdm(range(num_intervals)):\n",
    "    if 'wiki' in args.dataset_name:\n",
    "        split_text = eval_dataset.cl_texts[num_example].split('. ')[:-1]\n",
    "    if args.use_dataset or args.method == \"greedy\" or args.method == \"beam\":\n",
    "        if 'wikisection' in args.dataset_name:\n",
    "            k = 3\n",
    "        else:\n",
    "            k = 5\n",
    "        example = eval_dataset.examples[num_example][:k]\n",
    "        encoded_prompt = torch.tensor([example]).to(args.device)\n",
    "        input_ids = encoded_prompt\n",
    "        prompt_text = tokenizer.decode(example, skip_special_tokens=True)\n",
    "        print(\"Using eval prompt: {}\".format(prompt_text))\n",
    "    else: # stories\n",
    "        row = eval_dataset.cl_texts[num_example]\n",
    "        row = row.replace('<newline>', '')\n",
    "        row = row.replace(' , ', ', ')\n",
    "        row = row.strip() # NOTE: remove break line\n",
    "        row = ' '.join(row.split()) # remove multiple spaces\n",
    "        split_pattern = \". \"\n",
    "        split_text = row.split(split_pattern)[:-1]\n",
    "        split_text = [ _ + split_pattern for _ in split_text ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f53c6cd",
   "metadata": {
    "id": "9f53c6cd",
    "outputId": "958b40e9-7d4b-4e2c-92b0-7cfc718f5f49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[ USER ] Hello! I would like to get some movie tickets. ',\n",
       " '[ ASSISTANT ] Good morning! What movie would you like me to book tickets for? [ USER ] I would like to watch Uncut Gems. ',\n",
       " \"[ ASSISTANT ] Great! What's the address or name of the theater where you want to watch Uncut Gems? [ USER ] The AMC on Cypress. \",\n",
       " \"It's the only theater in my area. \",\n",
       " '[ ASSISTANT ] Awesome, what day would you like the tickets for? [ USER ] This Friday. ',\n",
       " '[ ASSISTANT ] The AMC at 1600 Calhoun Rd, Cypress, TX, has the following showtimes for Uncut Gems: 12:00 PM, 01:00 PM and 09:30 PM. ',\n",
       " '[ USER ] None of those work for me. ',\n",
       " \"Isn't there a showtime at 05:00 PM or 02:00 PM. \",\n",
       " \"[ ASSISTANT ] The theater you selected doesn't have those showtimes. \",\n",
       " \"I'm sorry. \",\n",
       " 'Would you like to see showtimes on other theaters or for other movies? [ USER ] Are there any showings of Doctor Doolittle in that same AMC? [ ASSISTANT ] For this Friday as well? [ USER ] Yes, at 05:00 PM or 02:00 PM. ',\n",
       " '[ ASSISTANT ] There is a 02:00 PM show for Doctor Doolittle. ',\n",
       " '[ USER ] Awesome! [ ASSISTANT ] How many tickets would you like me to book? [ USER ] Six. ',\n",
       " \"[ ASSISTANT ] I'm sorry, there are only four seats available for the 02:00 PM show. \",\n",
       " \"Would you like me to look at the Saturday shows instead? [ USER ] No, it's ok. \",\n",
       " \"I'll see if my friends want to watch something else. \"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af7eee3c",
   "metadata": {
    "id": "af7eee3c",
    "outputId": "c35f3996-975e-46b8-a930-1bbac77ca616"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1187"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c97df8ad",
   "metadata": {
    "id": "c97df8ad"
   },
   "outputs": [],
   "source": [
    "true_cl_feats = torch.stack(eval_dataset.cl_embeddings[num_example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfdb5f05",
   "metadata": {
    "id": "dfdb5f05",
    "outputId": "6ccca22e-91fb-41d4-f18f-06c84d5f51d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1025,  0.0956,  0.0594,  ...,  0.0926,  0.1122,  0.0967],\n",
       "        [-0.1025,  0.0956,  0.0594,  ...,  0.0926,  0.1122,  0.0967],\n",
       "        [-0.1025,  0.0956,  0.0594,  ...,  0.0926,  0.1122,  0.0967],\n",
       "        ...,\n",
       "        [-0.2416,  0.2438,  0.2398,  ...,  0.2663,  0.2442,  0.2473],\n",
       "        [-0.2416,  0.2438,  0.2398,  ...,  0.2663,  0.2442,  0.2473],\n",
       "        [-0.2416,  0.2438,  0.2398,  ...,  0.2663,  0.2442,  0.2473]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_cl_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35d464b1",
   "metadata": {
    "id": "35d464b1"
   },
   "outputs": [],
   "source": [
    "true_cl_feats = true_cl_feats[::args.split_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d5ea975",
   "metadata": {
    "id": "0d5ea975",
    "outputId": "dc20ba24-29ca-464f-f549-7312ea8a9137"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DENSITY ESTIMATE: [-0.52328944  0.5134945   0.5024361  -0.508544    0.5275813   0.5180528\n",
      "  0.5092071  -0.51341796  0.5401892   0.52739847 -0.5112348   0.53281057\n",
      " -0.51549774  0.5339563   0.5201655   0.5258357 ]\n",
      "DENSITY ESTIMATE STD: [0.20150964 0.19876935 0.1916553  0.1879684  0.19223699 0.19855234\n",
      " 0.19538742 0.19835728 0.2010545  0.19634782 0.19453451 0.19091173\n",
      " 0.1909538  0.18812436 0.19124323 0.19830342]\n"
     ]
    }
   ],
   "source": [
    "LABELS = ['TRUE CL', 'BRIDGE CL (DE)',\n",
    "                  # 'RANDOM CL'\n",
    "]\n",
    "# INTERPOLATION - BRIDGE\n",
    "print(f\"DENSITY ESTIMATE: {last_latent_mu}\")\n",
    "print(f\"DENSITY ESTIMATE STD: {last_latent_std}\")\n",
    "B_T = np.random.normal(loc=last_latent_mu, scale=last_latent_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4cbad24",
   "metadata": {
    "id": "b4cbad24"
   },
   "outputs": [],
   "source": [
    "num_sentences = len(true_cl_feats) if not args.split_sentences else int(len(true_cl_feats)/float(args.split_sentences))\n",
    "num_sentences *= args.multiply_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66355007",
   "metadata": {
    "id": "66355007"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    actual_inputs = eval_dataset.examples[num_example]\n",
    "except:\n",
    "    actual_inputs = eval_dataset.examples[-1]\n",
    "end = eval_dataset.get_end_points(actual_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cbe58e7d",
   "metadata": {
    "id": "cbe58e7d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_sentences = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1e3061d",
   "metadata": {
    "id": "c1e3061d"
   },
   "outputs": [],
   "source": [
    "if min_length > 1020:\n",
    "    actual_num_sentences = len(end)\n",
    "    ratio = (min_length+1)/(len(actual_inputs))\n",
    "    num_sentences = int(ratio*actual_num_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77cab19d",
   "metadata": {
    "id": "77cab19d",
    "outputId": "7465612d-be1f-48af-ad58-7d7c78e8c36b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original num sentences: 20\n",
      "Target num sentences: 40\n",
      "min length 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Original num sentences: {}\".format(len(end)))\n",
    "print(\"Target num sentences: {}\".format(num_sentences))\n",
    "print(\"min length\", min_length)\n",
    "end_lengths = [end[i] if i == 0 else end[i+1] - end[i] for i in range(len(end)-1)]\n",
    "end_lengths = (np.array(end_lengths)*(num_sentences/len(end)))\n",
    "#end_lengths = np.ones(end_lengths.shape)\n",
    "end_lengths = end_lengths.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1cfa2244",
   "metadata": {
    "id": "1cfa2244"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b79b89cf",
   "metadata": {
    "id": "b79b89cf"
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(train_dataset.cl_embeddings[0]),16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c0347d6",
   "metadata": {
    "id": "0c0347d6"
   },
   "outputs": [],
   "source": [
    "for row in range(len(train_dataset.cl_embeddings[0])):\n",
    "    X[row] = train_dataset.cl_embeddings[0][row].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb2cdadd",
   "metadata": {
    "id": "bb2cdadd",
    "outputId": "a9534051-b1f0-49d2-865b-1ca190202cf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24, 20, 42, 32, 24,  8, 78, 50, 62, 32, 14, 28, 30,  6, 22,  6, 62,\n",
       "       38, 16])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2115ac01",
   "metadata": {
    "id": "2115ac01"
   },
   "outputs": [],
   "source": [
    "def simulate_brownian_bridge_zoom(B_0, B_T, num_samples, sentence_lengths, zoom=1, dt=0.05, mu=0.0, sigma=1.0):\n",
    "    \"\"\"Run bridge forward pinned at B_0 and B_T\"\"\"\n",
    "    if isinstance(B_0, torch.Tensor):\n",
    "        B_0 = B_0.cpu().detach().numpy()\n",
    "    if isinstance(B_T, torch.Tensor):\n",
    "        B_T = B_T.cpu().detach().numpy()\n",
    "\n",
    "    bridge = [B_0]\n",
    "    x_t = np.copy(B_0)\n",
    "    for step in range(num_samples - 2): # number of sentences\n",
    "        dim = B_0.shape[-1]\n",
    "        noise = np.sqrt(dt)*sigma*np.random.normal(mu, sigma*zoom, dim)\n",
    "        t = step/num_samples\n",
    "        x_tp1 = x_t * (1- dt/(1-t)) + (dt/(1-t))*B_T + noise\n",
    "        length_idx = step % len(sentence_lengths)\n",
    "        bridge += [x_tp1] * sentence_lengths[length_idx]\n",
    "        x_t = x_tp1\n",
    "\n",
    "    length_idx = step % len(sentence_lengths)\n",
    "    bridge += [B_T] * sentence_lengths[length_idx]\n",
    "\n",
    "    return bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6adba918",
   "metadata": {
    "id": "6adba918"
   },
   "outputs": [],
   "source": [
    "def simulate_brownian_bridge_forced(B_0, B_T, num_samples, sentence_lengths, zoom=1, dt=0.05, mu=0.0, sigma=1.0):\n",
    "    \"\"\"Run bridge forward pinned at B_0 and B_T\"\"\"\n",
    "    if isinstance(B_0, torch.Tensor):\n",
    "        B_0 = B_0.cpu().detach().numpy()\n",
    "    if isinstance(B_T, torch.Tensor):\n",
    "        B_T = B_T.cpu().detach().numpy()\n",
    "\n",
    "    bridge = [B_0]\n",
    "    x_t = np.copy(B_0)\n",
    "    for step in range(num_samples - 2): # number of sentences\n",
    "        dim = B_0.shape[-1]\n",
    "        noise = np.sqrt(dt)*sigma*np.array([mu+sigma*zoom]*dim) #*np.random.normal(mu, sigma*zoom, dim)\n",
    "        t = step/num_samples\n",
    "        x_tp1 = x_t * (1- dt/(1-t)) + (dt/(1-t))*B_T + noise\n",
    "        length_idx = step % len(sentence_lengths)\n",
    "        bridge += [x_tp1] * sentence_lengths[length_idx]\n",
    "        x_t = x_tp1\n",
    "\n",
    "    length_idx = step % len(sentence_lengths)\n",
    "    bridge += [B_T] * sentence_lengths[length_idx]\n",
    "\n",
    "    return bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "gslwuGaINB0j",
   "metadata": {
    "id": "gslwuGaINB0j"
   },
   "outputs": [],
   "source": [
    "from generation_metrics import GenerationMetrics\n",
    "fname = args.model_name_or_path.split('/')[-2]\n",
    "args.encoder_type = 'contrast'\n",
    "gt_cl_tracker = GenerationMetrics(model=model, device=args.device,\n",
    "                                tokenizer=tokenizer, dataset_name=args.dataset_name,\n",
    "                                fname=fname+\"_trueCLEmbs_\" + args.method,\n",
    "                                model_args=args,\n",
    "                                subclass=\"GT\")\n",
    "random_cl_tracker = GenerationMetrics(model=model, device=args.device,\n",
    "                                tokenizer=tokenizer, dataset_name=args.dataset_name,\n",
    "                            model_args=args,\n",
    "                                fname=fname+\"_randomCLEmbs_\"+args.method,\n",
    "                                subclass=\"RANDOM\")\n",
    "bridge_cl_tracker = GenerationMetrics(model=model, device=args.device,\n",
    "                                tokenizer=tokenizer, dataset_name=args.dataset_name,\n",
    "                                fname=fname+\"_bridgeCLEmbs_\"+args.method,\n",
    "                            model_args=args,\n",
    "                                subclass=\"BRIDGE\")\n",
    "trackers = [gt_cl_tracker, bridge_cl_tracker,\n",
    "                    # random_cl_tracker\n",
    "                    ]\n",
    "def generate_txt(args, feats, trackers, model, bad_words_ids, min_length, tokenizer, eval_dataset, LABELS):\n",
    "    prompt_text = args.prompt if args.prompt else \"\"\n",
    "    for seq_i, (seq_cl_feats, tracker) in enumerate(zip(feats, trackers)):\n",
    "        cl_feats = seq_cl_feats[0] # Get the first sentence feat\n",
    "        prefix = args.prefix if args.prefix else args.padding_text\n",
    "        encoded_prompt = tokenizer.encode(prefix + prompt_text, add_special_tokens=True, return_tensors=\"pt\")\n",
    "        encoded_prompt = encoded_prompt.to(args.device)\n",
    "\n",
    "    if encoded_prompt.size()[-1] == 0:\n",
    "        input_ids = None\n",
    "    else:\n",
    "        input_ids = encoded_prompt\n",
    "\n",
    "    if 'filter' in args.dataset_name:\n",
    "        length = 1024\n",
    "    else:\n",
    "        length = 1024 # len(eval_dataset.examples[_])\n",
    "\n",
    "              # RESET THE CL INDEX\n",
    "    model.transformer._cur_cl_idx = 0\n",
    "    model.transformer._has_reset = False\n",
    "\n",
    "    max_length = min(length + len(encoded_prompt[0]), 1024)\n",
    "    if args.no_eos:\n",
    "        max_length = 1024\n",
    "\n",
    "    if args.method == \"sample\":\n",
    "        output_sequences = model.generate(\n",
    "                      input_ids=input_ids,\n",
    "                      section_ids=None,\n",
    "                      cl_feats=cl_feats, # .to(args.device),\n",
    "                      seq_cl_feats=seq_cl_feats,\n",
    "                      max_length=max_length,\n",
    "                      temperature=args.temperature,\n",
    "                      top_k=args.k,\n",
    "                      top_p=args.p,\n",
    "                      repetition_penalty=args.repetition_penalty,\n",
    "                      do_sample=True,\n",
    "                      num_return_sequences=args.num_return_sequences,\n",
    "                      bad_words_ids=bad_words_ids,\n",
    "                      min_length=min_length-50\n",
    "                  )\n",
    "    if len(output_sequences.shape) > 2:\n",
    "        output_sequences.squeeze_()\n",
    "\n",
    "    generated_sequences = []\n",
    "\n",
    "    for generated_sequence_idx, generated_sequence in enumerate(output_sequences):\n",
    "      # print(f\"=== GENERATED SEQUENCE {generated_sequence_idx + 1} ===\")\n",
    "        original = torch.clone(generated_sequence)\n",
    "        generated_sequence = generated_sequence.tolist()\n",
    "        print(\"Generated length: {}\".format(len(generated_sequence)))\n",
    "\n",
    "      # Decode text\n",
    "      # text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True)\n",
    "        text = tokenizer.decode(generated_sequence, skip_special_tokens=True)\n",
    "\n",
    "      # Remove all text after the stop token\n",
    "        text = text[: text.find(args.stop_token) if args.stop_token else None]\n",
    "\n",
    "      # Add the prompt at the beginning of the sequence. Remove the excess text that was used for pre-processing\n",
    "        total_sequence = (\n",
    "      prompt_text + text[len(tokenizer.decode(encoded_prompt[0], skip_special_tokens=True)) :]\n",
    "            )\n",
    "\n",
    "        gt_raw_seq = eval_dataset.raw_texts[num_example]\n",
    "        generated_sequences.append(total_sequence)\n",
    "        print(\"[ GENERATED FOR {} ]: {}\".format(LABELS[seq_i], total_sequence))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o96LeO_4M0qD",
   "metadata": {
    "id": "o96LeO_4M0qD"
   },
   "source": [
    "å‰é¢ç›´æŽ¥è¿è¡Œæ‰€æœ‰ï¼Œä»Žè¿™é‡Œå¼€å§‹åªè¿è¡Œä¸‹é¢è¿™ä¸ªå•å…ƒæ ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "OV0CGxAGM0S3",
   "metadata": {
    "id": "OV0CGxAGM0S3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_103907/2948241340.py:18: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  bridge_feats = torch.tensor(bridge_feats, dtype=true_cl_feats.dtype).to(args.device)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      "===========\n",
      "N(0,2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated length: 102\n",
      "[ GENERATED FOR BRIDGE CL (DE) ]: \"<|endoftext|>\"I would love to get to the movies tonight.  [ ASSISTANT ]  OK. And where will you be seeing the movie?  [ USER ]  Creek's End, Oregon.  [ ASSISTANT ]  Creekâ€™s End, Oregon. Got it. Is there a particular movie you have in mind?  [ USER ]  No wait, the visuals are so darned.  [ ASSISTANT ]  No problem.  [ USER ]  No problem.  [ ASSISTANT ]  No problem.  [ USER ]  No problem.  [ ASSISTANT ]  No problem.  [ ASSISTANT ]  No problem. \n",
      "===========\n",
      "===========\n",
      "N(0,3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated length: 427\n",
      "[ GENERATED FOR BRIDGE CL (DE) ]: \"<|endoftext|>\"My parentsâ€™s home is temporarily closed in Stoneyford Oregon due to a devastating pandemic and a pandemic of pandemic-like nature. The only information I can think for them is that they are going to be seeing Mulan this coming weekend.  [ ASSISTANT ]  Are there any documentary or animated movies that are playing?  [ USER ]  I heard the 19th Street movie, \"Bad Boys for Life\", is playing this weekend. Do you have a suggestion of a movie you would like to see?  [ USER ]  I can feel the smudge movie that is playing in theaters is pretty scary. What's the nature movie about?  [ ASSISTANT ]  I don't know if the movie is being shown locally, but I have heard about it from a neighbor. I think that people who actually live here would like that. Do you have ideas about that?  [ USER ]  What kind of movies do people really like? I like movies with good plots that have genuine characters.  [ ASSISTANT ]  I've heard of a movie called \"Beyond the Storm\" that's on the box and that it might have some good things about people. I also like films with good writing that have good acting. Could you tell me a bit more about the movies?  [ USER ]  I really enjoy good writing, as I would like more of a mystery movie with more person-like characters, and I want to see The Boy and the World tour.  [ USER ]  I think both of those are great. I think they really fit well. I also like the humor and humor in some of those movies.  [ ASSISTANT ]  I would be interested in checking for the World Tour. The World Tour is about movies and shows that are out now, since the West End is one of the best.  [ USER ]  I think that who is going the World Tour is the best to me. Would you please help me? I would like to have you check for the upcoming show.  [ ASSISTANT ]  Yes, I think you would be in luck. You can find out show times at Disney  [ USER ]  I would be happy to help you. You can find out show times at Goromney \n",
      "===========Fixed shaped Trajectory :\n",
      "1 sigma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated length: 60\n",
      "[ GENERATED FOR BRIDGE CL (DE) ]: \"<|endoftext|>\"I am thinking about seeing a movie tonight, please.  [ ASSISTANT ]  What movie do you have in mind?  [ USER ]  The Elizabeth Theatres.  [ ASSISTANT ]  They have 2 tickets available.  [ USER ]  Thank you.  [ ASSISTANT ]  They have been waiting in the line for you. \n",
      "===========\n",
      "===========\n",
      "2 sigma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated length: 65\n",
      "[ GENERATED FOR BRIDGE CL (DE) ]: \"<|endoftext|>\"Would you mind helping me to choose a movie to see at a AMC theater tonight?  [ ASSISTANT ]  Of course I can help you with that. I can provide your details in a few minutes, but it will be my best friend and wife go ahead.  [ ASSISTANT ]  No problem. Enjoy your movie! \n",
      "===========\n",
      "===========\n",
      "3 sigma\n",
      "Generated length: 38\n",
      "[ GENERATED FOR BRIDGE CL (DE) ]: \"<|endoftext|>\"I like those conversational films that leave you feeling happy and inspired.  [ ASSISTANT ]  Thank you for choosing me for the cinemopic option you have been so far. \n"
     ]
    }
   ],
   "source": [
    "#bridge_feats = simulate_brownian_bridge(B_0=true_cl_feats[0], B_T=B_T, num_samples=num_sentences,sentence_lengths=end_lengths)\n",
    "#print(\"===========different distribution: variance zoom\")\n",
    "#print(\"N(0,1)\")\n",
    "#bridge_feats = simulate_brownian_bridge_zoom(B_0=true_cl_feats[0], B_T=B_T, num_samples=num_sentences,sentence_lengths=end_lengths, zoom=1)\n",
    "\n",
    "#bridge_feats = torch.tensor(bridge_feats, dtype=true_cl_feats.dtype).to(args.device)\n",
    "# RANDOM\n",
    "#random_feats = torch.rand(true_cl_feats.shape).to(args.device)\n",
    "#feats = [true_cl_feats, bridge_feats, random_feats]\n",
    "\n",
    "#generate_txt(args, feats, trackers, model, bad_words_ids, min_length, tokenizer, eval_dataset, LABELS)\n",
    "\n",
    "print(\"===========\")\n",
    "print(\"===========\")\n",
    "print(\"N(0,2)\")\n",
    "bridge_feats = simulate_brownian_bridge_zoom(B_0=true_cl_feats[0], B_T=B_T, num_samples=num_sentences,sentence_lengths=end_lengths, zoom=2)\n",
    "\n",
    "bridge_feats = torch.tensor(bridge_feats, dtype=true_cl_feats.dtype).to(args.device)\n",
    "# RANDOM\n",
    "random_feats = torch.rand(true_cl_feats.shape).to(args.device)\n",
    "feats = [true_cl_feats, bridge_feats, random_feats]\n",
    "\n",
    "generate_txt(args, feats, trackers, model, bad_words_ids, min_length, tokenizer, eval_dataset, LABELS)\n",
    "\n",
    "print(\"===========\")\n",
    "print(\"===========\")\n",
    "print(\"N(0,3)\")\n",
    "bridge_feats = simulate_brownian_bridge_zoom(B_0=true_cl_feats[0], B_T=B_T, num_samples=num_sentences,sentence_lengths=end_lengths, zoom=3)\n",
    "\n",
    "bridge_feats = torch.tensor(bridge_feats, dtype=true_cl_feats.dtype).to(args.device)\n",
    "# RANDOM\n",
    "random_feats = torch.rand(true_cl_feats.shape).to(args.device)\n",
    "feats = [true_cl_feats, bridge_feats, random_feats]\n",
    "\n",
    "generate_txt(args, feats, trackers, model, bad_words_ids, min_length, tokenizer, eval_dataset, LABELS)\n",
    "\n",
    "print(\"===========Fixed shaped Trajectory :\")\n",
    "print(\"1 sigma\")\n",
    "bridge_feats = simulate_brownian_bridge_forced(B_0=true_cl_feats[0], B_T=B_T, num_samples=num_sentences,sentence_lengths=end_lengths, zoom=1)\n",
    "\n",
    "bridge_feats = torch.tensor(bridge_feats, dtype=true_cl_feats.dtype).to(args.device)\n",
    "# RANDOM\n",
    "random_feats = torch.rand(true_cl_feats.shape).to(args.device)\n",
    "feats = [true_cl_feats, bridge_feats, random_feats]\n",
    "\n",
    "generate_txt(args, feats, trackers, model, bad_words_ids, min_length, tokenizer, eval_dataset, LABELS)\n",
    "\n",
    "print(\"===========\")\n",
    "print(\"===========\")\n",
    "print(\"2 sigma\")\n",
    "bridge_feats = simulate_brownian_bridge_forced(B_0=true_cl_feats[0], B_T=B_T, num_samples=num_sentences,sentence_lengths=end_lengths, zoom=2)\n",
    "\n",
    "bridge_feats = torch.tensor(bridge_feats, dtype=true_cl_feats.dtype).to(args.device)\n",
    "# RANDOM\n",
    "random_feats = torch.rand(true_cl_feats.shape).to(args.device)\n",
    "feats = [true_cl_feats, bridge_feats, random_feats]\n",
    "\n",
    "generate_txt(args, feats, trackers, model, bad_words_ids, min_length, tokenizer, eval_dataset, LABELS)\n",
    "\n",
    "print(\"===========\")\n",
    "print(\"===========\")\n",
    "print(\"3 sigma\")\n",
    "bridge_feats = simulate_brownian_bridge_forced(B_0=true_cl_feats[0], B_T=B_T, num_samples=num_sentences,sentence_lengths=end_lengths, zoom=3)\n",
    "\n",
    "bridge_feats = torch.tensor(bridge_feats, dtype=true_cl_feats.dtype).to(args.device)\n",
    "# RANDOM\n",
    "random_feats = torch.rand(true_cl_feats.shape).to(args.device)\n",
    "feats = [true_cl_feats, bridge_feats, random_feats]\n",
    "\n",
    "generate_txt(args, feats, trackers, model, bad_words_ids, min_length, tokenizer, eval_dataset, LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576d281b",
   "metadata": {
    "id": "576d281b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "rOpRopaFOW-n",
   "metadata": {
    "id": "rOpRopaFOW-n"
   },
   "source": [
    "=============\n",
    "ä¸‹é¢çš„ä»£ç ä¸è¿è¡Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yvIDrm-ZOXEz",
   "metadata": {
    "id": "yvIDrm-ZOXEz"
   },
   "source": [
    "============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2849f4b6",
   "metadata": {
    "id": "2849f4b6"
   },
   "outputs": [],
   "source": [
    "from generation_metrics import GenerationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a2a33",
   "metadata": {
    "id": "d68a2a33"
   },
   "outputs": [],
   "source": [
    "fname = args.model_name_or_path.split('/')[-2]\n",
    "args.encoder_type = 'contrast'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0b17b5",
   "metadata": {
    "id": "ed0b17b5"
   },
   "outputs": [],
   "source": [
    "gt_cl_tracker = GenerationMetrics(model=model, device=args.device,\n",
    "                                tokenizer=tokenizer, dataset_name=args.dataset_name,\n",
    "                                fname=fname+\"_trueCLEmbs_\" + args.method,\n",
    "                                model_args=args,\n",
    "                                subclass=\"GT\")\n",
    "random_cl_tracker = GenerationMetrics(model=model, device=args.device,\n",
    "                                tokenizer=tokenizer, dataset_name=args.dataset_name,\n",
    "                            model_args=args,\n",
    "                                fname=fname+\"_randomCLEmbs_\"+args.method,\n",
    "                                subclass=\"RANDOM\")\n",
    "bridge_cl_tracker = GenerationMetrics(model=model, device=args.device,\n",
    "                                tokenizer=tokenizer, dataset_name=args.dataset_name,\n",
    "                                fname=fname+\"_bridgeCLEmbs_\"+args.method,\n",
    "                            model_args=args,\n",
    "                                subclass=\"BRIDGE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a1673",
   "metadata": {
    "id": "d60a1673"
   },
   "outputs": [],
   "source": [
    "trackers = [gt_cl_tracker, bridge_cl_tracker,\n",
    "                    # random_cl_tracker\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d6fd17",
   "metadata": {
    "id": "a6d6fd17"
   },
   "outputs": [],
   "source": [
    "prompt_text = args.prompt if args.prompt else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae24f3ca",
   "metadata": {
    "id": "ae24f3ca",
    "outputId": "f797631f-dd97-4ab5-f567-7b0cb091f8fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "for seq_i, (seq_cl_feats, tracker) in enumerate(zip(feats, trackers)):\n",
    "    cl_feats = seq_cl_feats[0] # Get the first sentence feat\n",
    "    prefix = args.prefix if args.prefix else args.padding_text\n",
    "    encoded_prompt = tokenizer.encode(prefix + prompt_text, add_special_tokens=True, return_tensors=\"pt\")\n",
    "    encoded_prompt = encoded_prompt.to(args.device)\n",
    "\n",
    "    if encoded_prompt.size()[-1] == 0:\n",
    "        input_ids = None\n",
    "    else:\n",
    "        input_ids = encoded_prompt\n",
    "\n",
    "    if 'filter' in args.dataset_name:\n",
    "        length = 1024\n",
    "    else:\n",
    "        length = 1024 # len(eval_dataset.examples[_])\n",
    "\n",
    "            # RESET THE CL INDEX\n",
    "    model.transformer._cur_cl_idx = 0\n",
    "    model.transformer._has_reset = False\n",
    "\n",
    "    max_length = min(length + len(encoded_prompt[0]), 1024)\n",
    "    if args.no_eos:\n",
    "        max_length = 1024\n",
    "\n",
    "    if args.method == \"sample\":\n",
    "        output_sequences = model.generate(\n",
    "                    input_ids=input_ids,\n",
    "                    section_ids=None,\n",
    "                    cl_feats=cl_feats, # .to(args.device),\n",
    "                    seq_cl_feats=seq_cl_feats,\n",
    "                    max_length=max_length,\n",
    "                    temperature=args.temperature,\n",
    "                    top_k=args.k,\n",
    "                    top_p=args.p,\n",
    "                    repetition_penalty=args.repetition_penalty,\n",
    "                    do_sample=True,\n",
    "                    num_return_sequences=args.num_return_sequences,\n",
    "                    bad_words_ids=bad_words_ids,\n",
    "                    min_length=min_length-50\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c84647",
   "metadata": {
    "id": "a0c84647"
   },
   "outputs": [],
   "source": [
    "if len(output_sequences.shape) > 2:\n",
    "    output_sequences.squeeze_()\n",
    "\n",
    "generated_sequences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bcf66c",
   "metadata": {
    "id": "01bcf66c",
    "outputId": "5e8dc28c-a2f8-46ff-fe1a-7f0b8caa527b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated length: 786\n",
      "[ GENERATED FOR BRIDGE CL (DE) ]: \"<|endoftext|>\"Oh how are we playing today  [ USER ]  I need to get a ticket there tonight  [ ASSISTANT ]  what theater did you want to see a movie in  [ USER ]  how about the blvd  [ ASSISTANT ]  what movie did you want to see  [ USER ]  i want to see can you help find a theater near san francisco theatre for tonight  [ ASSISTANT ]  which movie did you have a tickets for  [ USER ]  i want to see can you show off a good movie  [ ASSISTANT ]  what do you want to see  [ USER ]  i want to see movie about a funny movie  [ ASSISTANT ]  show off movie  [ USER ]  i want to see movie about a good movie  [ ASSISTANT ]  so are you sure  [ USER ]  as i have kids and want to go see good movies  [ ASSISTANT ]  ok i am gonna change movies a little bit  [ ASSISTANT ]  what do you want to change movies?  [ USER ]  i want to see kind action movie  [ ASSISTANT ]  ok do you have anything for show off movie?  [ USER ]  I am going to see a comedy movie  [ ASSISTANT ]  okay shall i book this for you  [ USER ]  I want to book this movie at the movie theater near me  [ ASSISTANT ]  okay am coming with two friends, me and my sweet mam and actually need 2 tickets  [ USER ]  am going with two friends  [ ASSISTANT ]  ok we are going to see Family Jewels and Not my problem  [ USER ]  ok can you please give details about both of them  [ ASSISTANT ]  ok so Family Jewels is an American movie that is rated R and has a Rotten Tomatoes rating of 69  [ USER ]  how about Not My Problem?  [ USER ]  i would like to see show off something interesting  [ ASSISTANT ]  tell me a little about it  [ USER ]  i want to remember the family jewels action movie  [ ASSISTANT ]  how about the rating nosed  [ USER ]  i want to know the rating about the movie - about a famous comedian  [ USER ]  i want to know the critics rating  [ USER ]  i want to know the rating about the movie about superman  [ ASSISTANT ]  it is about a famous comedian named Mike miel o ok  [ USER ]  is on the other side  [ USER ]  are you really interested its about a famous actor  [ USER ]  what screen the movie is play on by  [ USER ]  can you give details about the film by Charlie dolittle   [ USER ]  can you provide there movie starring in the movie  [ USER ]  can you give a synopsis on the movie  [ USER ]  i want to know the complete movies about the movie  [ ASSISTANT ]  sure can you give more details about the movie  [ USER ]  want to know the movie about comedy movie  [ USER ]  sure can you give your details about the movie  [ USER ]  what about the movie about family jewels  [ ASSISTANT ]  what about the movie about movie about family jewels  [ USER ]  can you give me the synopsis of the movie  [ USER ]  have you read the movie in the last few years?  [ ASSISTANT ]  please give details about the movie  [ USER ]  1. Not My Problem - Comedy - rated PG-13 - Rotten Tomatoes 72% 2. Not My Problem - Horror - rated R - Rotten Tomatoes 72% - - A troubled teen tries to convince his depressed elderly neighbor that things are not what they seem. - Stars Matt Damon and Noah Schnapp. - Stars Matt Damon and Noah Schnapp.  [ USER ]  i want to ticket it  [ ASSISTANT ]  what time it is showing  [ USER ]  what theater it is showing it is also showing at amc mountain 16  [ ASSISTANT ]  i want to go and see it at imc mountain 16  [ USER ]  ok can you provide details about the theater  [ USER ]  can you provide details about the time it is showing  [ USER ]  please book it at the movie theater near me  [ ASSISTANT ]  what day it is showing it is showing it is at 12pm  [ USER ]  i want to go and see it late in the day  [ ASSISTANT ]  i am sorry but i can not book the ticket for you at this time  [ USER ]  ok please let me know the details that i can provide for ticket reservation  [ USER ]  ok thank you  [ USER ]  that is my ticket reservation number \n"
     ]
    }
   ],
   "source": [
    "for generated_sequence_idx, generated_sequence in enumerate(output_sequences):\n",
    "    # print(f\"=== GENERATED SEQUENCE {generated_sequence_idx + 1} ===\")\n",
    "    original = torch.clone(generated_sequence)\n",
    "    generated_sequence = generated_sequence.tolist()\n",
    "    print(\"Generated length: {}\".format(len(generated_sequence)))\n",
    "\n",
    "    # Decode text\n",
    "    # text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True)\n",
    "    text = tokenizer.decode(generated_sequence, skip_special_tokens=True)\n",
    "\n",
    "    # Remove all text after the stop token\n",
    "    text = text[: text.find(args.stop_token) if args.stop_token else None]\n",
    "\n",
    "    # Add the prompt at the beginning of the sequence. Remove the excess text that was used for pre-processing\n",
    "    total_sequence = (\n",
    "    prompt_text + text[len(tokenizer.decode(encoded_prompt[0], skip_special_tokens=True)) :]\n",
    "           )\n",
    "\n",
    "    gt_raw_seq = eval_dataset.raw_texts[num_example]\n",
    "    generated_sequences.append(total_sequence)\n",
    "    print(\"[ GENERATED FOR {} ]: {}\".format(LABELS[seq_i], total_sequence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dc88ec",
   "metadata": {
    "id": "38dc88ec"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9813d1f9",
   "metadata": {
    "id": "9813d1f9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa7753e",
   "metadata": {
    "id": "6aa7753e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lmvs",
   "language": "python",
   "name": "lmvs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
